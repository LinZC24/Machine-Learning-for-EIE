{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F  #激活函数\n",
    "from torch import nn\n",
    "from torch import optim  #优化器\n",
    "from torchvision import transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(root_dir):\n",
    "  paths=[]\n",
    "  labels=[]\n",
    "  for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "      paths.append(os.path.join(root, file))\n",
    "      index=file.find('_')\n",
    "      labels.append(file[:index])\n",
    "  return paths,labels\n",
    "\n",
    "def get_folder(root_dir):\n",
    "  folder_name=[]\n",
    "  for entry in os.listdir(root_dir):\n",
    "    full_path=os.path.join(root_dir, entry)\n",
    "    if os.path.isdir(full_path):\n",
    "      folder_name.append(entry)\n",
    "  return folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, root_dir, transform=None):\n",
    "    #初始化数据集，包含一系列图片与对应标签\n",
    "    super().__init__()\n",
    "    #self.data_path=root_dir\n",
    "    self.transform=transform\n",
    "    dataset=get_folder(root_dir)\n",
    "    path_data, labels=get_data(root_dir)\n",
    "    self.path=path_data\n",
    "    img_data=[]\n",
    "    for i in path_data:\n",
    "      img=Image.open(i)\n",
    "      img=img.convert('L')\n",
    "      img_data.append(img)\n",
    "      img.close()\n",
    "    self.data=img_data\n",
    "    self.label=labels\n",
    "    if(dataset[0][-4:]=='test'):\n",
    "      test_data, test_labels=get_data(dataset[0])\n",
    "      train_data, train_labels=get_data(dataset[1])\n",
    "    else:\n",
    "      test_data, test_labels=get_data(dataset[1])\n",
    "      train_data, train_labels=get_data(dataset[0])\n",
    "    img_train=[]\n",
    "    img_test=[]\n",
    "    for j in train_data:\n",
    "      img=Image.open(j)\n",
    "      img=img.convert('L')\n",
    "      img_train.append(img)\n",
    "      img.close()\n",
    "    for k in test_data:\n",
    "      img=Image.open(k)\n",
    "      img=img.convert('L')\n",
    "      img_test.append(img)\n",
    "      img.close()\n",
    "    self.train_label=train_labels\n",
    "    self.train=img_train\n",
    "    self.test_label=test_labels\n",
    "    self.test=img_test\n",
    "    #raise NotImplementedError\n",
    "  \n",
    "  def __len__(self):\n",
    "    #返回数据集大小\n",
    "    return len(self.data)\n",
    "    #raise NotImplementedError\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    #返回第index个样本\n",
    "    img=self.data[index]\n",
    "    label=self.label[index]\n",
    "    path=self.path[index]\n",
    "    if(self.transform):\n",
    "      img=self.transform(img)\n",
    "    item={'image':img, 'label':label, 'path':path}\n",
    "    return item\n",
    "    #raise NotImplementedError\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(dataset):\n",
    "  expect_sum, var_sum=torch.zeros(3), torch.zeros(3)\n",
    "  size=len(dataset)\n",
    "  transform=tf.Compose([tf.ToTensor(), tf.Normalize((0,), (1,))])\n",
    "  for i in range(size):\n",
    "    image=Image.open(dataset[i]['path'])\n",
    "    img_tensor=transform(image)\n",
    "    expect_sum=expect_sum+torch.mean(img_tensor, dim=[1,2])\n",
    "    var_sum=var_sum+torch.mean(img_tensor**2, dim=[1,2])\n",
    "  mean=expect_sum/size\n",
    "  std=var_sum/size\n",
    "  return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCNModel\n",
    "def get_dataloader(train=True):\n",
    "  if(train):\n",
    "    dataset=CifarDataset('..\\cifar10\\cifar10_'+'train')\n",
    "  else:\n",
    "    dataset=CifarDataset('..\\cifar10\\cifar10_'+'test')\n",
    "  mean, std=get_mean(dataset)\n",
    "  t=tf.Compose([tf.ToTensor(), tf.Normalize(mean, std), tf.Grayscale(num_output_channels=1)])\n",
    "  i=0\n",
    "  dataset_o=[]\n",
    "  d=[]\n",
    "  label_o=[]\n",
    "  for i in range(len(dataset)):\n",
    "    img=Image.open(dataset[i]['path'])    \n",
    "    img=t(img)\n",
    "    d.append(img)\n",
    "    x=0\n",
    "    if(dataset[i]['label']=='airplane'):x=0\n",
    "    elif(dataset[i]['label']=='automobile'):x=1\n",
    "    elif(dataset[i]['label']=='bird'):x=2\n",
    "    elif(dataset[i]['label']=='cat'):x=3\n",
    "    elif(dataset[i]['label']=='deer'):x=4\n",
    "    elif(dataset[i]['label']=='dog'):x=5\n",
    "    elif(dataset[i]['label']=='frog'):x=6\n",
    "    elif(dataset[i]['label']=='horse'):x=7\n",
    "    elif(dataset[i]['label']=='ship'):x=8\n",
    "    else:x=9\n",
    "    label_o.append(x)\n",
    "  dataset_o=list(zip(d, label_o))\n",
    "  if train:\n",
    "    batch_size=train_batch_size \n",
    "  else:\n",
    "    batch_size=test_batch_size\n",
    "  dataloader=torch.utils.data.DataLoader(dataset_o, batch_size=batch_size, shuffle=True)\n",
    "  return dataloader\n",
    "\n",
    "train_batch_size=128\n",
    "test_batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(FCNModel, self).__init__()\n",
    "    self.fc1=torch.nn.Linear(32*32*1, 128)\n",
    "    self.fc2=torch.nn.Linear(128, 32)\n",
    "    self.fc3=torch.nn.Linear(32,10)\n",
    "\n",
    "  def forward(self, input_data):\n",
    "    x=input_data.view(-1, 32*32*1)\n",
    "    x=self.fc1(x)\n",
    "    x=F.relu(x)\n",
    "    x=self.fc2(x)\n",
    "    x=F.relu(x)\n",
    "    out=F.log_softmax(x, dim=-1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model=FCNModel()\n",
    "fcn_model=fcn_model.to(device)\n",
    "optimizer=torch.optim.Adam(fcn_model.parameters(), lr=0.001)\n",
    "train_loss_list=[]\n",
    "train_count_list=[]\n",
    "def fcntrain(epoch):\n",
    "  fcn_model.train(True)\n",
    "  train_dataloader=get_dataloader(True)\n",
    "  print(\"start training\")\n",
    "  for id,sample in enumerate(train_dataloader):\n",
    "    data, label=sample\n",
    "    label_t=torch.tensor(label) \n",
    "    data=data.to(device)\n",
    "    label_t=label_t.to(device)  \n",
    "    optimizer.zero_grad()\n",
    "    out=fcn_model(data)\n",
    "    loss=F.nll_loss(out, label_t)\n",
    "    loss.to(device)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if id%200==0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,  id * len(data), len(train_dataloader.dataset),100. * id / len(train_dataloader), loss.item()))\n",
    "      train_loss_list.append(loss.item())\n",
    "      train_count_list.append(id*train_batch_size+(epoch-1)*len(train_dataloader))\n",
    "  print('end training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcntest():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    fcn_model.eval()  #设置为评估模式\n",
    "    test_dataloader = get_dataloader(train=False)  #导入测试数据集\n",
    "    with torch.no_grad():  #不需要计算梯度\n",
    "        for data, label in test_dataloader:\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "            output = fcn_model(data)\n",
    "            test_loss += F.nll_loss(output, label, reduction='sum').item()  \n",
    "            pred = output.data.max(1, keepdim=True)[1] #获取最大值的位置\n",
    "            correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_dataloader.dataset)  #计算平均损失\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 3.508729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzc\\AppData\\Local\\Temp\\ipykernel_24244\\2380585826.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_t=torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.096507\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.758363\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.673875\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.741757\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.642946\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.492710\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.633654\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.596887\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.626502\n",
      "end training\n",
      "\n",
      "Test set: Avg. loss: 1.6464, Accuracy: 4316/10000 (43.16%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    fcntrain(i)\n",
    "fcntest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnnModel\n",
    "class cnnModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(cnnModel, self).__init__()\n",
    "    self.conv1=nn.Conv2d(1, 6, 5, padding=2)\n",
    "    self.conv2=nn.Conv2d(6, 18, 5)\n",
    "    self.fc1=nn.Linear(18*6*6, 128)\n",
    "    self.dropout=nn.Dropout(p=0.2)\n",
    "    self.fc2=nn.Linear(128, 32)\n",
    "    self.fc3=nn.Linear(32, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x=F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "    x=F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "    x=x.view(-1, self.num_flat_features(x))\n",
    "    x=F.relu(self.fc1(x))\n",
    "    x=self.dropout(x)\n",
    "    x=F.relu(self.fc2(x))\n",
    "    x=self.fc3(x)\n",
    "    out=F.log_softmax(x, dim=-1)\n",
    "    return out\n",
    "  \n",
    "  def num_flat_features(self, x):\n",
    "    size=x.size()[1:]\n",
    "    num=1\n",
    "    for s in size:\n",
    "      num=num*s\n",
    "    return num\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=cnnModel()\n",
    "cnn=cnn.to(device)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(),lr= 0.001) \n",
    "train_loss_list = []\n",
    "train_count_list = []\n",
    "train_batch_size = 128\n",
    "test_batch_size = 64\n",
    "def cnntrain(epoch):\n",
    "  cnn.train(True)\n",
    "  train_dataloader=get_dataloader(True)\n",
    "  print(\"start training\")\n",
    "  for id,sample in enumerate(train_dataloader):\n",
    "    data, label=sample\n",
    "    label_t=torch.tensor(label)\n",
    "    data=data.to(device)\n",
    "    label_t=label_t.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out=cnn(data)\n",
    "    loss=F.nll_loss(out, label_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if id%200==0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,  id * len(data), len(train_dataloader.dataset),100. * id / len(train_dataloader), loss.item()))\n",
    "      train_loss_list.append(loss.item())\n",
    "      train_count_list.append(id*train_batch_size+(epoch-1)*len(train_dataloader))\n",
    "  print(\"end training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnntest():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    cnn.eval()  #设置为评估模式\n",
    "    test_dataloader = get_dataloader(train=False)  #导入测试数据集\n",
    "    with torch.no_grad():  #不需要计算梯度\n",
    "        for data, target in test_dataloader:\n",
    "            data=data.to(device)\n",
    "            target=target.to(device)\n",
    "            output = cnn(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  \n",
    "            pred = output.data.max(1, keepdim=True)[1] #获取最大值的位置,[batch_size,1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_dataloader.dataset)  #计算平均损失\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 1.100840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzc\\AppData\\Local\\Temp\\ipykernel_24244\\755914583.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_t=torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 1.377514\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.136201\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.165915\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.077296\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.924600\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.987410\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.227819\n",
      "end training\n",
      "start training\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.080285\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.175485\n",
      "end training\n",
      "\n",
      "Test set: Avg. loss: 1.0542, Accuracy: 6325/10000 (63.25%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    cnntrain(i)\n",
    "cnntest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
